# best practices for testing

## purpose of testing:
- think use cases, edge cases, and play with the business logic / model you've defined
- define use cases, edge cases, and previous failure points explicitly for future reference
- automate checking that:
  - code complies with spec (i.e., all use cases and requirements are satisfied)
  - regressions will not occur
  - predicted error cases are covered

## three test types:
- unit tests
  - test precisely scoped business logic, mocking out all dependencies
  - purpose is to test that the unit/function of logic that you're defining does the logic in it correctly
- integration tests
  - test end to end logic OR test boundaries between calling a dependent service
  - for example:
    - test boundaries with a dependent api
      - test that we are communicating w/ database correctly
      - test that we are
    - test end to end logic
      - test that a handler acts correctly in different cases
      - test that a highly composed business logic function produces the correct results in all cases
- acceptance tests
  - test that the deployed product works
  - ideally: test an end to end pipeline of each use case it needs to support
    - note: typically its sufficient to trust that integration tests have already tested the use cases and then all we need to test is that the lambda can be hit

// todo: add examples to the above
// todo: finesse the above definitions now that we're formally defining them

## pattern

- each test type gets its own file extension
  - unit -> `.test.ts` (the default extension)
  - integration -> `.integration.test.ts`
  - acceptance -> `.acceptance.test.ts`
- each test type gets its own config (e.g., specify what extension to use)
  - `jest.unit.config`
  - `jest.integration.config`
  - `jest.acceptance.config`
- each test type gets its own environment setup file (e.g., global mocks, or checks, etc)
  - `jest.unit.env`
  - `jest.integration.env`
  - `jest.acceptance.env`
